{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "with open('./dataset/imdb_trainX.txt',encoding=\"utf-8\") as file:\n",
    "    reviews = file.readlines()\n",
    "    print(type(reviews))\n",
    "with open('./dataset/imdb_trainY.txt',encoding=\"utf8\") as f:\n",
    "    y = f.readlines()\n",
    "print(int(y[100]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem.snowball import PorterStemmer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'loved',\n",
       " 'this',\n",
       " 'movie',\n",
       " 'since',\n",
       " 'i',\n",
       " 'was',\n",
       " '7',\n",
       " 'and',\n",
       " 'i',\n",
       " 'saw',\n",
       " 'it',\n",
       " 'on',\n",
       " 'the',\n",
       " 'opening',\n",
       " 'day',\n",
       " 'it',\n",
       " 'was',\n",
       " 'so',\n",
       " 'touching',\n",
       " 'and',\n",
       " 'beautiful',\n",
       " 'i',\n",
       " 'strongly',\n",
       " 'recommend',\n",
       " 'seeing',\n",
       " 'for',\n",
       " 'all',\n",
       " 'it',\n",
       " 's',\n",
       " 'a',\n",
       " 'movie',\n",
       " 'to',\n",
       " 'watch',\n",
       " 'with',\n",
       " 'your',\n",
       " 'family',\n",
       " 'by',\n",
       " 'far',\n",
       " 'my',\n",
       " 'mpaa',\n",
       " 'rating',\n",
       " 'pg',\n",
       " '13',\n",
       " 'for',\n",
       " 'thematic',\n",
       " 'elements',\n",
       " 'prolonged',\n",
       " 'scenes',\n",
       " 'of',\n",
       " 'disastor',\n",
       " 'nudity',\n",
       " 'sexuality',\n",
       " 'and',\n",
       " 'some',\n",
       " 'language']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews[0]=reviews[0].replace(\"<br /><br /\",\" \")\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "tokenized_words = tokenizer.tokenize(reviews[0].lower())\n",
    "tokenized_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['loved',\n",
       " 'movie',\n",
       " 'since',\n",
       " '7',\n",
       " 'saw',\n",
       " 'opening',\n",
       " 'day',\n",
       " 'touching',\n",
       " 'beautiful',\n",
       " 'strongly',\n",
       " 'recommend',\n",
       " 'seeing',\n",
       " 'movie',\n",
       " 'watch',\n",
       " 'family',\n",
       " 'far',\n",
       " 'mpaa',\n",
       " 'rating',\n",
       " 'pg',\n",
       " '13',\n",
       " 'thematic',\n",
       " 'elements',\n",
       " 'prolonged',\n",
       " 'scenes',\n",
       " 'disastor',\n",
       " 'nudity',\n",
       " 'sexuality',\n",
       " 'language']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_words = [w for w in tokenized_words if w not in sw]\n",
    "clean_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'love movi sinc 7 saw open day touch beauti strongli recommend see movi watch famili far mpaa rate pg 13 themat element prolong scene disastor nuditi sexual languag'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps = PorterStemmer()\n",
    "stemmed_words = []\n",
    "for w in clean_words:\n",
    "    stemmed_words.append(ps.stem(w))\n",
    "clean_words = ' '.join(stemmed_words)\n",
    "clean_words\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data_cleaner as dc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "rev_test = reviews[10:210]\n",
    "clean_test = [dc.clean_text(w) for w in rev_test]\n",
    "reviews_train = reviews[:1000]\n",
    "cleaned_data = [dc.clean_text(r) for r in reviews_train]\n",
    "y = [int(i) for i in y]\n",
    "Y = y[:1000]\n",
    "Y = np.array(Y)\n",
    "Y_test = np.array(y[10:210])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = cv.fit_transform(cleaned_data).toarray()\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 13242)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = cv.transform(clean_test).toarray()\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb.fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 8,  8, 10,  8,  8,  8, 10, 10,  7,  7,  8, 10,  8,  9,  8, 10, 10,\n",
       "       10,  7,  9,  9,  7, 10, 10, 10, 10,  7,  9, 10,  9, 10,  9, 10,  8,\n",
       "        8, 10,  8, 10,  8,  8,  8,  7,  8,  8,  7,  7, 10, 10,  7, 10,  7,\n",
       "        9, 10,  8,  7, 10, 10, 10,  7, 10, 10, 10,  8, 10, 10, 10, 10,  8,\n",
       "       10, 10,  9,  9,  8,  8,  9,  7,  9, 10, 10,  7,  7, 10, 10,  7,  7,\n",
       "       10,  8,  8, 10, 10, 10,  7, 10,  8, 10,  8,  8,  8,  9,  8, 10, 10,\n",
       "       10, 10,  7, 10, 10, 10, 10, 10, 10, 10, 10,  8,  8,  8,  8,  8, 10,\n",
       "       10, 10, 10,  8,  8,  8,  7, 10,  7, 10, 10,  8, 10,  9,  9, 10,  7,\n",
       "        9, 10,  8, 10,  8,  7,  8, 10,  7,  8, 10, 10, 10, 10, 10,  9,  9,\n",
       "       10,  8, 10, 10, 10, 10,  9, 10, 10, 10, 10, 10,  9,  7, 10, 10,  7,\n",
       "       10,  7,  8, 10,  7,  7, 10, 10, 10, 10,  8,  9,  8, 10, 10,  7, 10,\n",
       "        9, 10, 10,  9, 10, 10, 10, 10,  7,  7,  7, 10, 10])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 8,  8, 10,  8,  8,  8,  9, 10,  7,  7,  8,  7,  8,  9,  8,  7, 10,\n",
       "       10,  7,  9,  9,  7, 10, 10, 10, 10,  7,  9, 10,  9, 10,  9, 10,  8,\n",
       "        8, 10,  8, 10,  8,  8,  8,  7,  8,  8,  7,  7, 10, 10,  7, 10,  7,\n",
       "        9, 10,  8,  7, 10, 10, 10,  7, 10, 10,  8,  8,  8, 10, 10, 10,  8,\n",
       "       10, 10,  9,  9,  8,  8,  9,  7,  9, 10, 10,  7,  7, 10, 10,  7,  7,\n",
       "       10,  8,  8, 10, 10, 10,  7, 10,  8, 10,  8,  8,  8,  9,  8, 10, 10,\n",
       "        9, 10,  7, 10, 10, 10,  8, 10, 10, 10, 10,  8,  8,  8,  8,  8, 10,\n",
       "       10, 10, 10,  8,  8,  8,  7, 10,  7, 10, 10,  8, 10,  9,  9, 10,  7,\n",
       "        9, 10,  8,  9,  8,  7,  8, 10,  7,  8, 10, 10, 10, 10, 10,  9,  9,\n",
       "       10,  8, 10, 10, 10, 10,  9,  8, 10, 10,  7,  9,  9,  7, 10, 10,  7,\n",
       "       10,  7,  8, 10,  7,  7, 10, 10, 10, 10,  8,  9,  8, 10, 10,  7, 10,\n",
       "        9, 10,  8,  9, 10, 10,  7,  8,  7,  7,  7, 10,  7])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.924"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb.score(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'definit great movi want continu see movi reason strike cord even though scene scott glenn still make winch watch love music'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_test[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7,  8,  9, 10])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
